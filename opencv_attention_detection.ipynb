{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// load openCV libraries and headers\n",
    "#pragma cling add_library_path(\"/usr/local/Cellar/opencv@3/3.4.5/lib/\")\n",
    "#pragma cling add_include_path(\"/usr/local/Cellar/opencv@3/3.4.5/include/\")\n",
    "#pragma cling add_include_path(\"/usr/local/Cellar/opencv@3/3.4.5/include/opencv2/\")\n",
    "#pragma cling load(\"/usr/local/Cellar/opencv@3/3.4.5/lib/libopencv_aruco.3.4.5.dylib\")\n",
    "#pragma cling load(\"/usr/local/Cellar/opencv@3/3.4.5/lib/libopencv_dnn_objdetect.3.4.5.dylib\")\n",
    "#pragma cling load(\"/usr/local/Cellar/opencv@3/3.4.5/lib/libopencv_dnn.3.4.5.dylib\")\n",
    "#pragma cling load(\"/usr/local/Cellar/opencv@3/3.4.5/lib/libopencv_objdetect.3.4.5.dylib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// openCV specific includes\n",
    "#include <opencv2/opencv.hpp>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// standard C++ headers used later in the notebook\n",
    "#include <iostream>\n",
    "#include <string>\n",
    "#include <vector>\n",
    "#include <sstream>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Starting from version 3.3, OpenCV supports Caffe\n",
    "std::cout <<\"OpenCV version: \" << CV_VERSION << std::endl;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// define some helper structs representing faces and eyes\n",
    "struct cv_circle {\n",
    "    int x;\n",
    "    int y;\n",
    "    cv_circle(int x_, int y_) : x(x_), y(y_) {}\n",
    "};"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct cv_rect {\n",
    "    int x_left_bottom;\n",
    "    int y_left_bottom;\n",
    "    int x_right_top;\n",
    "    int y_right_top;\n",
    "    cv_rect(int x_left_bottom_, int y_left_bottom_, int x_right_top_, int y_right_top_) :\n",
    "        x_left_bottom(x_left_bottom_),\n",
    "        y_left_bottom(y_left_bottom_),\n",
    "        x_right_top(x_right_top_),\n",
    "        y_right_top(y_right_top_) {}\n",
    "};"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// input: a rectangle representing a face\n",
    "//        an STL vector containing eyes\n",
    "// output: if eyes are symmetric in respect to vertical line with x=const=middle-rect\n",
    "//         [yes, no]\n",
    "bool analyze_attention(const std::vector<cv_circle>& eyes, const cv_rect& face) {\n",
    "    if(eyes.size() == 2) {\n",
    "        std::cout << \"eye-1 = [\" << eyes[0].x << \", \" << eyes[0].y << \"]\" << std::endl;\n",
    "        std::cout << \"eye-2 = [\" << eyes[1].x << \", \" << eyes[1].y << \"]\" << std::endl;\n",
    "        \n",
    "        int rect_middle_x = face.x_left_bottom + (face.x_right_top - face.x_left_bottom) / 2;\n",
    "        std::cout << \"face = [\" << face.x_left_bottom << \", \" << face.y_left_bottom << \"], right-top = [\" << face.x_right_top << \", \" << face.y_right_top << \"] -- middle x =  \" << rect_middle_x << std::endl;\n",
    "\n",
    "        // eye-1 = [407, 181]\n",
    "        // eye-2 = [491, 32687]\n",
    "        // face = [354, 81], right-top = [533, 347] -- middle x =  443\n",
    "        int x_dist_1 = std::abs(rect_middle_x - eyes[0].x);\n",
    "        int x_dist_2 = std::abs(rect_middle_x - eyes[1].x);\n",
    "        \n",
    "        int x_distance_diff_threshold_pixel = 20;\n",
    "        std::cout << \"diff = \" << std::abs(x_dist_1-x_dist_2) << std::endl;\n",
    "        if(std::abs(x_dist_1-x_dist_2) < x_distance_diff_threshold_pixel)\n",
    "            return true;\n",
    "        \n",
    "        return false;\n",
    "    }\n",
    "    return false;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define WEB_CAM 0\n",
    "#define USB_CAM 17\n",
    "\n",
    "// showing a plain video stream using a standard webcam or a different camera.\n",
    "void show_video_stream() {\n",
    "\n",
    "    //Open the default video camera\n",
    "    cv::VideoCapture cap(WEB_CAM);\n",
    "\n",
    "    // if not success, exit program\n",
    "    if (cap.isOpened() == false) {\n",
    "        std::cout << \"Cannot open the video camera\" << std::endl;\n",
    "        return -1;\n",
    "    } \n",
    "\n",
    "    double dWidth = cap.get(cv::CAP_PROP_FRAME_WIDTH); //get the width of frames of the video\n",
    "    double dHeight = cap.get(cv::CAP_PROP_FRAME_HEIGHT); //get the height of frames of the video\n",
    "\n",
    "    std::cout << \"Resolution of the video : \" << dWidth << \" x \" << dHeight << std::endl;\n",
    "\n",
    "    cv::Mat edges;\n",
    "    cv::namedWindow(\"edges\",1);\n",
    "    for(;;)\n",
    "    {\n",
    "        cv::Mat frame;\n",
    "        cap >> frame; // get a new frame from camera\n",
    "        cv::imshow(\"Video\", frame);\n",
    "        if(cv::waitKey(30) >= 0) break;\n",
    "    }\n",
    "\n",
    "    // the camera will be deinitialized automatically in VideoCapture destructor\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv::dnn::Net initialize_network() {\n",
    "    // The .prototxt file defines the model architecture (the layers)\n",
    "    cv::String model = \"/Users/robert/Downloads/deep-learning-face-detection/deploy.prototxt.txt\"; \n",
    "    \n",
    "    // The .caffemodel contains the weights for the actual layers\n",
    "    // res10_300x300_ssd_iter_140000.caffemodel: The model was created with SSD framework using ResNet-10 like architecture as a backbone. Channels count in ResNet-10 convolution layers was significantly dropped (2x- or 4x- fewer channels). The model was trained in Caffe framework on some huge and available online dataset.\n",
    "    cv::String config = \"/Users/robert/Downloads/deep-learning-face-detection/res10_300x300_ssd_iter_140000.caffemodel\";\n",
    "    \n",
    "    CV_Assert(!model.empty());\n",
    "    \n",
    "    // initialize network\n",
    "    cv::dnn::Net net = cv::dnn::readNetFromCaffe(model, config);\n",
    "    \n",
    "    return net;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int initialize_cascade_classifier(\n",
    "    cv::CascadeClassifier& cascade,\n",
    "    cv::CascadeClassifier& nestedCascade) {\n",
    "    \n",
    "    std::string cascadeName = \"/Users/robert/Downloads/deep-learning-face-detection/haarcascade_frontalface_alt.xml\";\n",
    "    std::string nestedCascadeName = \"/Users/robert/Downloads/deep-learning-face-detection/haarcascade_eye_tree_eyeglasses.xml\";\n",
    "    if (!nestedCascade.load(cv::samples::findFile(nestedCascadeName))) {\n",
    "        std::cout << \"ERROR: Could not load classifier cascade for nested objects\" << std::endl;\n",
    "        return -1;\n",
    "    }\n",
    "    \n",
    "    if (!cascade.load(cv::samples::findFile(cascadeName))) {\n",
    "        std::cerr << \"ERROR: Could not load classifier cascade\" << std::endl;\n",
    "        return -1;\n",
    "    }\n",
    "    \n",
    "    return 1;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// return detected eyes in form of a STL vector of opencv circles\n",
    "// using Cascade classifiers\n",
    "std::vector<cv_circle> detect_eyes(\n",
    "    cv::CascadeClassifier& cascade,\n",
    "    cv::CascadeClassifier& nestedCascade,\n",
    "    cv::Mat& img,\n",
    "    bool draw_face = false) {\n",
    "    \n",
    "    std::vector<cv_circle> result;\n",
    "    \n",
    "    double scale = 1.3;\n",
    "    \n",
    "    double t = 0;\n",
    "    std::vector<cv::Rect> faces, faces2;\n",
    "    \n",
    "    const static cv::Scalar colors[] =\n",
    "    {\n",
    "        cv::Scalar(255,0,0),\n",
    "        cv::Scalar(255,128,0),\n",
    "        cv::Scalar(255,255,0),\n",
    "        cv::Scalar(0,255,0),\n",
    "        cv::Scalar(0,128,255),\n",
    "        cv::Scalar(0,255,255),\n",
    "        cv::Scalar(0,0,255),\n",
    "        cv::Scalar(255,0,255)\n",
    "    };\n",
    "    \n",
    "    cv::Mat gray, smallImg;\n",
    "    cv::cvtColor(img, gray, cv::COLOR_BGR2GRAY);\n",
    "    \n",
    "    double fx = 1 / scale;\n",
    "    \n",
    "    cv::resize(gray, smallImg, cv::Size(), fx, fx, cv::INTER_LINEAR_EXACT);\n",
    "    cv::equalizeHist(smallImg, smallImg);\n",
    "    \n",
    "    t = (double)cv::getTickCount();\n",
    "    cascade.detectMultiScale(smallImg, faces,\n",
    "        1.1, 2, 0\n",
    "        //|CASCADE_FIND_BIGGEST_OBJECT\n",
    "        //|CASCADE_DO_ROUGH_SEARCH\n",
    "        |cv::CASCADE_SCALE_IMAGE,\n",
    "        cv::Size(30, 30) );\n",
    "\n",
    "    t = (double)cv::getTickCount() - t;\n",
    "    printf( \"detection time = %g ms\\n\", t*1000/cv::getTickFrequency());\n",
    "    \n",
    "    for ( size_t i = 0; i < faces.size(); i++ )\n",
    "    {\n",
    "        cv::Rect r = faces[i];\n",
    "        cv::Mat smallImgROI;\n",
    "        std::vector<cv::Rect> nestedObjects;\n",
    "        cv::Point center;\n",
    "        cv::Scalar color = colors[i%8];\n",
    "        int radius;\n",
    "        \n",
    "        if(draw_face) {\n",
    "            double aspect_ratio = (double)r.width/r.height;\n",
    "            if( 0.75 < aspect_ratio && aspect_ratio < 1.3 )\n",
    "            {\n",
    "                center.x = cvRound((r.x + r.width*0.5)*scale);\n",
    "                center.y = cvRound((r.y + r.height*0.5)*scale);\n",
    "                radius = cvRound((r.width + r.height)*0.25*scale);\n",
    "                cv::circle( img, center, radius, color, 3, 8, 0 );\n",
    "            }\n",
    "            else\n",
    "                cv::rectangle( img, cv::Point(cvRound(r.x*scale), cvRound(r.y*scale)),\n",
    "                           cv::Point(cvRound((r.x + r.width-1)*scale), cvRound((r.y + r.height-1)*scale)),\n",
    "                           color, 3, 8, 0);\n",
    "        }\n",
    "        \n",
    "        if( nestedCascade.empty() )\n",
    "            continue;\n",
    "        \n",
    "        smallImgROI = smallImg(r);\n",
    "        nestedCascade.detectMultiScale( smallImgROI, nestedObjects,\n",
    "            1.1, 2, 0\n",
    "            //|CASCADE_FIND_BIGGEST_OBJECT\n",
    "            //|CASCADE_DO_ROUGH_SEARCH\n",
    "            //|CASCADE_DO_CANNY_PRUNING\n",
    "            |cv::CASCADE_SCALE_IMAGE,\n",
    "            cv::Size(30, 30) );\n",
    "        \n",
    "        for ( size_t j = 0; j < nestedObjects.size(); j++ ) {\n",
    "            cv::Rect nr = nestedObjects[j];\n",
    "            center.x = cvRound((r.x + nr.x + nr.width*0.5)*scale);\n",
    "            center.y = cvRound((r.y + nr.y + nr.height*0.5)*scale);\n",
    "            radius = cvRound((nr.width + nr.height)*0.25*scale);\n",
    "            cv::circle(img, center, radius, color, 3, 8, 0);\n",
    "            \n",
    "            result.push_back(cv_circle(center.x, center.y));\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return result;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "void add_label(cv::Mat& frame,\n",
    "               bool attention_given,\n",
    "               float confidence,\n",
    "               int xLeftBottom,\n",
    "               int yLeftBottom) {\n",
    "    std::stringstream ss;\n",
    "    ss.str(\"\");\n",
    "    ss << static_cast<int>(confidence*100);\n",
    "    std::stringstream ss2;\n",
    "    ss2.str(\"\");\n",
    "    ss2 << attention_given;\n",
    "    cv::String conf(ss.str());\n",
    "    cv::String attention(ss2.str());\n",
    "    cv::String label = \"Face: \" + conf + \"% | attention: \" + attention;\n",
    "    int baseLine = 0;\n",
    "    cv::Size labelSize = cv::getTextSize(label, cv::FONT_HERSHEY_SIMPLEX, 0.5, 1, &baseLine);\n",
    "    cv::rectangle(frame,\n",
    "                  cv::Rect(cv::Point(xLeftBottom, yLeftBottom-labelSize.height),\n",
    "                      cv::Size(labelSize.width, labelSize.height + baseLine)),\n",
    "                  cv::Scalar(255,255,255), cv::FILLED);\n",
    "\n",
    "    cv::putText(frame, label, cv::Point(xLeftBottom, yLeftBottom), cv::FONT_HERSHEY_SIMPLEX, 0.5, cv::Scalar(0,0,0));\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define WEB_CAM 0\n",
    "#define USB_CAM 17\n",
    "\n",
    "void video_face_detect() {\n",
    "    \n",
    "    bool use_cascade_classifier_only = false;\n",
    "    \n",
    "    cv::CascadeClassifier cascade;\n",
    "    cv::CascadeClassifier nestedCascade;\n",
    "    \n",
    "    if(initialize_cascade_classifier(cascade, nestedCascade) == -1)\n",
    "        return;\n",
    "    \n",
    "    cv::dnn::Net net = initialize_network();\n",
    "    if(net.empty()) {\n",
    "        std::cout << \"Could not initialize network!\" << std::endl;\n",
    "    }\n",
    "    \n",
    "    static const std::string windown_name = \"OpenCV/Caffe face detection demo\";\n",
    "    cv::namedWindow(windown_name, 1);\n",
    "    \n",
    "    //Open the default video camera\n",
    "    cv::VideoCapture cap(WEB_CAM);\n",
    "\n",
    "    // if not success, exit program\n",
    "    if (cap.isOpened() == false) {\n",
    "        std::cout << \"Cannot open the video camera\" << std::endl;\n",
    "        return -1;\n",
    "    }\n",
    "    \n",
    "    const size_t in_width = 300;\n",
    "    const size_t in_height = 300;\n",
    "    const double in_scaling_factor = 1.0;\n",
    "    // Mean subtraction is used to help combat illumination changes\n",
    "    const cv::Scalar mean_val(104.0, 177.0, 123.0);\n",
    "    const double min_confidence = 0.5;\n",
    "    \n",
    "    for(int k = 0; k < 500; ++k) {\n",
    "        cv::Mat frame;\n",
    "        cap >> frame; // get a new frame from camera\n",
    "        \n",
    "        if(frame.empty()) {\n",
    "            cv::waitKey();\n",
    "            break;\n",
    "        }\n",
    "        \n",
    "        if(use_cascade_classifier_only) {\n",
    "            detect_eyes(cascade, nestedCascade, frame, true);\n",
    "            cv::imshow(windown_name, frame);\n",
    "            if(cv::waitKey(30) >= 0) {\n",
    "                break;\n",
    "            }\n",
    "        }\n",
    "        else {\n",
    "            // process the image in the DNN algorithm:\n",
    "            //  to send the image to the DNN we convert the OpenCV Mat structure to a DNN structure\n",
    "            //  called a \"blob\". OpenCV uses the Mat class to hold the blob.\n",
    "            cv::Mat input_blob;\n",
    "            cv::dnn::blobFromImage(frame, input_blob, in_scaling_factor, cv::Size(in_width, in_height), mean_val, false, false);\n",
    "\n",
    "            // now the frame is converted into a blob. let's feed it to the DNN and make detection using the forward function\n",
    "            net.setInput(input_blob);\n",
    "            cv::Mat detection = net.forward();\n",
    "            cv::Mat detectionMat(detection.size[2], detection.size[3], CV_32F, detection.ptr<float>());\n",
    "\n",
    "            for(int i = 0; i < detectionMat.rows; ++i) {\n",
    "                float confidence = detectionMat.at<float>(i, 2);\n",
    "                if(confidence > min_confidence) {\n",
    "                    std::cout << \"confidence for detection #\" << i << \" = \" << confidence << std::endl;\n",
    "\n",
    "                    int xLeftBottom = static_cast<int>(detectionMat.at<float>(i, 3) * frame.cols);\n",
    "                    int yLeftBottom = static_cast<int>(detectionMat.at<float>(i, 4) * frame.rows);\n",
    "                    int xRightTop = static_cast<int>(detectionMat.at<float>(i, 5) * frame.cols);\n",
    "                    int yRightTop = static_cast<int>(detectionMat.at<float>(i, 6) * frame.rows);\n",
    "                    \n",
    "                    cv::Rect object((int)xLeftBottom,\n",
    "                                    (int)yLeftBottom,\n",
    "                                    (int)(xRightTop-xLeftBottom),\n",
    "                                    (int)(yRightTop-yLeftBottom) );\n",
    "\n",
    "                    cv::rectangle(frame, object, cv::Scalar(0,255,0));     \n",
    "                    \n",
    "                    int xLeftBottom_roi = xLeftBottom - 20;\n",
    "                    int yLeftBottom_roi = yLeftBottom - 20;\n",
    "                    int xRightTop_roi = xRightTop + 20;\n",
    "                    int yRightTop_roi = yRightTop + 20;\n",
    "                    \n",
    "                    cv::Rect rect_roi((int)xLeftBottom_roi,\n",
    "                                      (int)yLeftBottom_roi,\n",
    "                                      std::min(frame.cols - xLeftBottom_roi, (int)(xRightTop_roi-xLeftBottom_roi)),\n",
    "                                      std::min(frame.rows - yLeftBottom_roi, (int)(yRightTop_roi-yLeftBottom_roi)));\n",
    "\n",
    "                    std::vector<cv_circle> eyes;\n",
    "                    \n",
    "                    // to reduce computational complexity we try to crop the original image to the defined ROI, i.e., the detected face\n",
    "                    std::cout << xLeftBottom << \", \" << yLeftBottom << \", \" << xRightTop-xLeftBottom << \", \" << yRightTop-yLeftBottom << \" / mat rows = \" << frame.rows << \", frame.cols \" << frame.cols << std::endl;\n",
    "                    if(0 <= rect_roi.x && 0 <= rect_roi.width && rect_roi.x + rect_roi.width <= frame.cols && 0 <= rect_roi.y && 0 <= rect_roi.height && rect_roi.y + rect_roi.height <= frame.rows) {\n",
    "                        cv::Mat crop = frame(rect_roi);\n",
    "                        eyes = detect_eyes(cascade, nestedCascade, crop, false);\n",
    "                    } else {\n",
    "                        eyes = detect_eyes(cascade, nestedCascade, frame, false);\n",
    "                    }\n",
    "                    \n",
    "                    cv_rect rec(0, 0, xRightTop_roi-xLeftBottom_roi, yRightTop_roi-yLeftBottom_roi);     \n",
    "                    bool attention_given = analyze_attention(eyes, rec);\n",
    "                    std::cout << \"XX2 attention_given = \" << attention_given << std::endl;\n",
    "                    \n",
    "                    std::cout << std::endl;\n",
    "                    add_label(frame, attention_given, confidence, xLeftBottom, yLeftBottom);\n",
    "                    \n",
    "                    cv::imshow(windown_name, frame);\n",
    "                    if(cv::waitKey(30) >= 0)\n",
    "                        break;\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_face_detect();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// interesting resources:\n",
    "\n",
    "// Jupyter kernel for C++\n",
    "// -> https://github.com/jupyter-xeus/xeus-cling\n",
    "\n",
    "// various approaches for face detection\n",
    "// -> https://medium.com/@walmaly/let-the-face-meets-machine-learning-8dd18ff96efd\n",
    "\n",
    "\n",
    "// more infos around Caffe, DNN, etc.\n",
    "\n",
    "// When using OpenCV’s deep neural network module with Caffe models, you’ll need two sets of files:\n",
    "// - The .prototxt file(s) which define the model architecture (i.e., the layers themselves)\n",
    "// - The .caffemodel file which contains the weights for the actual layers\n",
    "\n",
    "// OpenCV’s deep learning face detector is based on the Single Shot Detector (SSD) framework with a ResNet\n",
    "//  base network (unlike other OpenCV SSDs that you may have seen which typically use MobileNet as the base network).\n",
    "\n",
    "// Cascade classifier:\n",
    "// https://docs.opencv.org/3.4.5/d4/d26/samples_2cpp_2facedetect_8cpp-example.html#a20\n",
    "\n",
    "// https://books.google.com/books?id=ZVqWDwAAQBAJ&pg=PA437&lpg=PA437&dq=res10_300x300_ssd_iter_140000.caffemodel&source=bl&ots=CkV8wVZ1X0&sig=ACfU3U2xCG9kvGB2HWI0AG7tgwv85fSQ-g&hl=en&sa=X&ved=2ahUKEwjz1KnIoZvqAhUDYKwKHR8tB-4Q6AEwCXoECAsQAQ#v=onepage&q=res10_300x300_ssd_iter_140000.caffemodel&f=false\n",
    "\n",
    "// mean subtraction:\n",
    "// https://www.pyimagesearch.com/2017/11/06/deep-learning-opencvs-blobfromimage-works/\n",
    "//  Mean subtraction is used to help combat illumination changes in the input images in our dataset. We can therefore view mean subtraction as a technique used to aid our Convolutional Neural Networks.\n",
    "\n",
    "// general overview of ML and DNN: http://adilmoujahid.com/posts/2016/06/introduction-deep-learning-python-caffe/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "C++17",
   "language": "C++17",
   "name": "xcpp17"
  },
  "language_info": {
   "codemirror_mode": "text/x-c++src",
   "file_extension": ".cpp",
   "mimetype": "text/x-c++src",
   "name": "c++",
   "version": "17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
